{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intelligenza Artificiale - Lab 3"
      ],
      "metadata": {
        "id": "JvtOrzgBKYWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In questo laboratorio esploreremo un problema di classificazione realistico che coinvolge dati ad alta dimensionalità, ovvero, la classificazione di immagini. Le simulazioni si baseranno su un dataset molto popolare chiamato [MNIST](https://en.wikipedia.org/wiki/MNIST_database), che contiene 70.000 immagini di cifre manoscritte con le relative etichette (da 0 a 9).\n",
        "\n",
        "Per risolvere questo problema implementeremo una semplice architettura di ***deep learning***, ovvero un MLP dotato di vari strati nascosti. Vedremo anche come implementare una variante **convoluzionale**, particolarmente adatta al processamento di immagini.\n",
        "\n",
        "Vedremo infine come simulare un compito percettivo, ricavando una curva psicometrica che descrive la sensibilità del modello rispetto al rumore contenuto negli stimoli visivi."
      ],
      "metadata": {
        "id": "Rb-uqCAXyNwE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cc7QAjS7HQM8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Lambda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "mnist_train = MNIST(root=\"../mnist\",\n",
        "                    train=True,      # dati di training\n",
        "                    download=True)\n",
        "mnist_test = MNIST(root=\"../mnist\",\n",
        "                    train=False,     # dati di test\n",
        "                    download=True)"
      ],
      "metadata": {
        "id": "yUpfMz0zLG1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_tr_in, mnist_tr_out = mnist_train.data.numpy(), mnist_train.targets.numpy()\n",
        "mnist_te_in, mnist_te_out = mnist_test.data.numpy(), mnist_test.targets.numpy()"
      ],
      "metadata": {
        "id": "D9Y1dzMXLO0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le immagini sono salvate in formato bi-dimensionale (matrici 28x28). Tuttavia la rete neurale \"fully connected\" riceve in input vettori uni-dimensionali, quindi come primo step \"linearizziamo\" le matrici con l'operazione di `reshape`, ottenendo vettori di 784 elementi.\n",
        "\n",
        "Inoltre le immagini sono salvate in un formato convenzionale per le immagini, dove ciascun pixel può assumere valori tra 0 e 255. Come secondo step normalizziamo quindi i valori nell'intervallo tra 0 e 1, semplicemente dividendo per 255."
      ],
      "metadata": {
        "id": "Oak2OZQnzYQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_tr_in = mnist_tr_in.reshape(60000, 28*28)\n",
        "mnist_te_in = mnist_te_in.reshape(10000, 28*28)"
      ],
      "metadata": {
        "id": "TgiPM3v2NI6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_tr_in = mnist_tr_in / 255\n",
        "mnist_te_in = mnist_te_in / 255"
      ],
      "metadata": {
        "id": "GYsSs5H-NZk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo ora un MLP con due strati nascosti, lasciando i parametri di apprendimento di default, e procediamo con l'apprendimento."
      ],
      "metadata": {
        "id": "5jRiUD5E0Ng3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# con 10 iterazioni la convergenza è già abbastanza buona e l'algoritmo\n",
        "# impiega circa 3 minuti a completare l'esecuzione. Volendo una convergenza\n",
        "# migliore si dovrebbe aumentare il numero di iterazioni (e di hidden layers)\n",
        "\n",
        "random_state = 0\n",
        "\n",
        "MLP = MLPClassifier(hidden_layer_sizes=(500, 500),\n",
        "                    max_iter = 10,\n",
        "                    random_state=random_state)"
      ],
      "metadata": {
        "id": "RwcXBG18Mhbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLP = MLP.fit(mnist_tr_in, mnist_tr_out)"
      ],
      "metadata": {
        "id": "c7tdXY6QM_W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possiamo ora procedere visualizzando la curva dell'errore, l'accuratezza media e la matrice di confusione."
      ],
      "metadata": {
        "id": "xs0jfuxF0ofa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sklearn.metrics as metrics"
      ],
      "metadata": {
        "id": "X0YtmR4yOSyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plt.plot(range(MLP.n_iter_), MLP.loss_curve_)\n",
        "_ = plt.xlabel(\"Epoca\")\n",
        "_ = plt.ylabel(\"Loss\")\n",
        "_ = plt.title(\"Loss durante l'apprendimento\")\n",
        "plt.ylim(0, 0.3);"
      ],
      "metadata": {
        "id": "4ID8BtSHOJmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLP.score(mnist_te_in, mnist_te_out)"
      ],
      "metadata": {
        "id": "3jIQT9ThNz8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = MLP.predict(mnist_te_in)"
      ],
      "metadata": {
        "id": "wdoRCGJ7N5G3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = metrics.ConfusionMatrixDisplay.from_predictions(mnist_te_out, test_predictions)"
      ],
      "metadata": {
        "id": "FQ_v-w2QOjzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Curve psicometriche: resistenza al rumore"
      ],
      "metadata": {
        "id": "b-3tAtcPqxWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo una funzione che prende in input una matrice di dati (nel nostro caso, immagini MNIST) ed un livello di rumore desiderato e restituisce una versione rumorosa delle immagini."
      ],
      "metadata": {
        "id": "9OSVJZYKv0h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _inject_Gaussian_noise(mnist_data, noise_level):\n",
        "  # creiamo una matrice di rumore della dimensione dell'intero dataset dato in input alla funzione\n",
        "  dataset_size = mnist_data.shape\n",
        "  random_gaussian_vector = np.random.normal(loc = 0, scale = noise_level, size = dataset_size)\n",
        "  # aggiungiamo il rumore ai pixel originali, tagliando i valori minori di 0 o maggiori di 1\n",
        "  noisy_images = mnist_data + random_gaussian_vector\n",
        "  noisy_images = np.clip(noisy_images,0,1)\n",
        "  return noisy_images"
      ],
      "metadata": {
        "id": "6GWpVh9q3uJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_level = 0.3  # varianza della Gaussiana\n",
        "mnist_te_with_noise = _inject_Gaussian_noise(mnist_te_in, noise_level)"
      ],
      "metadata": {
        "id": "IlH8D94W4Sf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plt.imshow(mnist_te_with_noise[0].reshape(28, 28), cmap=\"gray\")"
      ],
      "metadata": {
        "id": "0pR_UBHuX0oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possiamo richiamare la funzione appena creata per più volte, incrementando di volta in volta il livello di rumore. In questo modo possiamo vedere come il numero di errori cresce all'aumentare del rumore."
      ],
      "metadata": {
        "id": "Bzy8owMOxF30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "livelli_di_rumore = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "percentuale_errori = []\n",
        "\n",
        "# testiamo il modello su stimoli contenenti un livello di rumore crescente:\n",
        "for livello in livelli_di_rumore:\n",
        "  mnist_con_rumore = _inject_Gaussian_noise(mnist_te_in, livello)\n",
        "  accuratezza = MLP.score(mnist_con_rumore, mnist_te_out)\n",
        "  percentuale_errori.append(1-accuratezza)\n"
      ],
      "metadata": {
        "id": "btg93Demajlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plt.plot(livelli_di_rumore, percentuale_errori)\n",
        "_ = plt.xlabel(\"Rumore\")\n",
        "_ = plt.ylabel(\"Percentuale di errori\")\n",
        "_ = plt.title(\"Curva psicometrica MLP\")"
      ],
      "metadata": {
        "id": "-FIiiPxCbr-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network"
      ],
      "metadata": {
        "id": "zqKH93-qqpth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo ora una semplice variante convoluzionale dell'architettura di deep learning. La rete pre-impostata ha un singolo layer convoluzionale (con 32 filtri) ed un layer fully-connected con 50 neuroni nascosti."
      ],
      "metadata": {
        "id": "GuPFA7QzyZ3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "rZADr-f2kXET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential(\n",
        "    [keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
        "     keras.layers.Flatten(),\n",
        "     keras.layers.Dense(units=50, activation='softmax')]\n",
        ")"
      ],
      "metadata": {
        "id": "lpT6yPD6kZCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              metrics=[\"accuracy\"],\n",
        "              loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "wRVNKHicmCBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La CNN richiede dati di input 2D, a differenza di MLP che richiede vettori 1D. Dobbiamo quindi riportare i dati in formato immagine bi-dimensionale:"
      ],
      "metadata": {
        "id": "7umc4LnvyvNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_tr_in_conv = mnist_tr_in.reshape(-1, 28, 28, 1)\n",
        "mnist_te_in_conv = mnist_te_in.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "id": "sRad8og0m1h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(mnist_tr_in_conv, mnist_tr_out, epochs=5)"
      ],
      "metadata": {
        "id": "jdBTAZ_vlyhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plt.plot(range(5), history.history['loss'])\n",
        "_ = plt.xlabel(\"Epoca\")\n",
        "_ = plt.ylabel(\"Loss\")\n",
        "_ = plt.title(\"Loss durante l'apprendimento\")"
      ],
      "metadata": {
        "id": "HQpbbZ0Opv0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(mnist_te_in_conv, mnist_te_out)"
      ],
      "metadata": {
        "id": "aFQ_8Ymzn2o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions_conv = model.predict(mnist_te_in_conv)"
      ],
      "metadata": {
        "id": "Sr03eR8zsjxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = metrics.ConfusionMatrixDisplay.from_predictions(mnist_te_out,\n",
        "                                                    test_predictions_conv.argmax(axis=1))"
      ],
      "metadata": {
        "id": "yYpVY-4_sjJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resistenza al rumore"
      ],
      "metadata": {
        "id": "s4iNci98q3-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "livelli_di_rumore = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "percentuale_errori_conv = []\n",
        "\n",
        "# testiamo il modello su stimoli contenenti un livello di rumore crescente:\n",
        "for livello in livelli_di_rumore:\n",
        "  mnist_con_rumore = _inject_Gaussian_noise(mnist_te_in, livello)\n",
        "  mnist_con_rumore_conv = mnist_con_rumore.reshape(-1, 28, 28, 1)\n",
        "  _ , accuratezza = model.evaluate(mnist_con_rumore_conv, mnist_te_out)\n",
        "  percentuale_errori_conv.append(1-accuratezza)\n"
      ],
      "metadata": {
        "id": "vHxSzgYKopof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plt.plot(livelli_di_rumore, percentuale_errori, label = 'MLP')\n",
        "_ = plt.plot(livelli_di_rumore, percentuale_errori_conv, label = 'CNN')\n",
        "_ = plt.legend()\n",
        "_ = plt.xlabel(\"Rumore\")\n",
        "_ = plt.ylabel(\"Errore\")\n",
        "_ = plt.title(\"Resistenza al rumore MLP vs. CNN\")"
      ],
      "metadata": {
        "id": "qmxEiWeapJXJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}